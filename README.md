
# A-TDOM: Active TDOM via On-the-Fly 3DGS
Yiwei Xu, Xiang Wang, Yifei Yu, Wentian Gan, Luca Morelli, Giulio Perda, Xiongwu Xiao, Zongqian Zhan, Xin Wang, and Fabio Remondino

[![arxiv](https://img.shields.io/badge/arxiv-2406.15643-red)](https://arxiv.org/abs/2509.12759)

![image](0.png)

# Important Notice (Please Read before Start!!!)

The Python environment configuration differs significantly between **Windows** and **Linux** in this project,
and the supported functionalities also vary across the two platforms.

If you intend to run the project on **Windows** and execute it concurrently with **On-the-Fly SfM**,
thereby enabling true *simultaneous camera pose acquisition, 3DGS training, and TDOM generation*,
please refer to [Windows Env Setting](#windows-env-setting) and [Windows Run](#windows-run).

If you intend to run the project on **Linux** and only perform `Simulation Experiments`,
please refer to [Linux Env Setting](#linux-env-setting) and [Linux Run](#linux-run).

# Cloning the Repository

```shell
# SSH
git clone git@github.com:xywjohn/A-TDOM.git --recursive
```
or
```shell
# HTTPS
git clone https://github.com/xywjohn/A-TDOM --recursive
```

After that, please manually decompress the diff-gaussian-rasterization.zip, 
fused-ssim.zip and simple-knn.zip archive located under the `submodules` directory.

# Windows Env Setting

If you are configuring the Python environment for **A-TDOM** on **Windows**,
please **do not use** `environment.yml`. Instead, set up the environment using the following commands:

```shell
conda create -n ATDOM python=3.9.0
conda install cudatoolkit=11.6 -c conda-forge
conda install pytorch=1.12.1 torchvision=0.13.1 torchaudio=0.12.1 -c pytorch

pip install plyfile
pip install tqdm
pip install opencv-python
pip install lpips
pip install scikit-image

pip install submodules/diff-gaussian-rasterization
pip install submodules/simple-knn
pip install submodules/fused-ssim
```

Since **PyTorch3D** does not provide precompiled binaries for **Windows**, you need to manually download and build it from source.
Please refer to the official repository: [PyTorch3D GitHub](https://github.com/facebookresearch/pytorch3d).
When compiling **PyTorch3D**, please pay close attention to the compatibility between
**CUB**, **PyTorch3D**, and the version of **Visual Studio**. In this project, we use **PyTorch3D v0.7.1** together with **CUB v1.15.0**,
and **Visual Studio 2019 or 2022** is recommended.

# Windows Run

When running on **Windows**, we provide visualization support for **TDOM generation**,
allowing the results of **orthographic splatting** from the current 3DGS field to be displayed during 3DGS progressive training.
In addition, **A-TDOM** can be executed concurrently with **On-the-Fly SfM**
to achieve true *simultaneous camera pose acquisition, 3DGS training, and TDOM generation*.
Alternatively, **A-TDOM** can also be run after **On-the-Fly SfM** has finished
exporting all intermediate results, enabling **simulation experiments**.

In this project, we provide executable versions of **On-the-Fly SfM**,
which are stored in the corresponding folder with the same name.
If you would like to learn how to export the intermediate results, please refer to [Data Preparation](#data-preparation).

## Before Run A-TDOM Concurrently With On-the-Fly SfM

If you would like to run **A-TDOM** concurrently with **On-the-Fly SfM**, 
you need to start **On-the-Fly SfM** first (please refer to [Data Preparation](#data-preparation) for usage details),
and then launch **A-TDOM**. If all image data are captured and stored in `Image_Folder_Path` and 
**On-the-Fly SfM** saves all SfM results in `Source_Path_Dir`, your directory structure should be organized as follows:

*****************************************

.../Image_Folder_Path\
=> NULL (Waiting for new images)

.../Source_Path_Dir\
=> GaussianSplatting\
==> NULL (Waiting for SfM results from On-the Fly SfM)
...

*****************************************

## Before Simulation Experiments

`Simulation Experiments` require running **On-the-Fly SfM** in advance to generate and export the intermediate results.
If the intermediate results generated by **On-the-Fly SfM** are stored in `Source_Path_Dir`,
and the image data are stored in `Image_Folder_Path`,
your directory structure should be organized as follows:

*****************************************

.../Image_Folder_Path\
=> 0001.jpg, 0002.jpg, 0003.jpg, ...

.../Source_Path_Dir\
=> GaussianSplatting\
==> 3\
===> bin, ...\
==> 4\
===> bin, ...\
...

*****************************************

## 3DGS Training and TDOM Generation

If you would like to output the results of **3DGS training** to `Model_Path_Dir`, 
please run the following command to perform 3DGS training:

```shell
python Window-On-the-Fly-Train.py 
  --Source_Path_Dir .../your_path 
  --Model_Path_Dir .../your_path 
  --Image_Folder_Path .../your_path 
  --OriginImageHeight [int] 
  --OriginImageWidth [int] 
  --points_per_triangle [int] 
  --LogMaskThreshold [float] 
  --Use_Tri_Mask
```

If you would like to generate **TDOM** simultaneously during training,
please run the following command:

```shell
python Window-On-the-Fly-Train.py 
  --Source_Path_Dir .../your_path 
  --Model_Path_Dir .../your_path 
  --Image_Folder_Path .../your_path 
  --OriginImageHeight [int] 
  --OriginImageWidth [int] 
  --points_per_triangle [int] 
  --LogMaskThreshold [float] 
  --show_TDOM
  --Use_Tri_Mask
  --render_TDOM 
  --GSD_x [float] 
  --GSD_y [float]
```

<details>
<summary><span style="font-weight: bold;">Necessary command Line Arguments for ContinuosProgressiveTrain4.py</span></summary>

  #### --Source_Path_Dir {str}
  Path to the source directory containing all camera pose information and sparse point cloud.
  #### --Model_Path_Dir {str}
  Path where the trained model should be stored.
  #### --Image_Folder_Path {str}
  Path to directory containing all image data.
  #### --IterationFirstScene {int}
  Training iterations for initial training phase.
  #### --FinalOptimizationIterations {int}
  Training iterations for final refinement phase.
  #### --StartFromImageNo {int}
  It indicates from which image the progressive training begins. This image and all the images before it are used for scene initialization.
  #### --OriginImageHeight {int}
  The original image height input into On-Fly SfM.
  #### --OriginImageWidth {int}
  The original image width input into On-Fly SfM.
  #### --points_per_triangle {int}
  The number of points collected in each triangle when conducting point sampling based on the Delunay triangulation.
  #### --LogMaskThreshHold {float}
  Gradient difference threshold used to determine whether new Gaussians should be added. A larger value results in fewer Gaussians being added, while a smaller value leads to more.
  #### --show_TDOM
  When enabled, the generated **TDOM** is continuously visualized during progressive 3DGS training.
  #### --Use_Tri_Mask
  When enabled, use the mask generated from Delaunay Triangulation for 3DGS training.
  #### --NoDebug
  When enabled, rendering quality evaluation is disabled during progressive 3DGS training.
  #### --render_RGB
  When enabled, the newly added image is rendered after completing the training stage for each new image.
  #### --render_TDOM
  When enabled, orthogonal splatting is performed on the current 3DGS field after each training stage, and a TDOM is generated.
  #### --GetDemo
  When enabled, a demo is generated based on the rendered results during training. This option must be used together with `--render_RGB` or `--render_TDOM`.
  #### --GSD_x {float}
  GSD of the generated TDOM along the Y-axis. If set to `0`, the GSD will be automatically determined.
  #### --GSD_y {float}
  GSD of the generated TDOM along the Y-axis. If set to `0`, the GSD will be automatically determined.

</details>

## Example

We use the **phantom3-ieu** dataset
(you can download it [here](https://www.adv-ci.com/blog/source/npu-drone-map-dataset/))
as an example. The following command demonstrates how to perform 3DGS training with simultaneous TDOM generation:

```shell
python Window-On-the-Fly-Train.py 
  --Source_Path_Dir .../phantom3-ieu 
  --Model_Path_Dir .../phantom3-ieu 
  --Image_Folder_Path .../images 
  --OriginImageHeight 1049 
  --OriginImageWidth 1870 
  --points_per_triangle 30 
  --LogMaskThreshold 0.15 
  --show_TDOM
  --Use_Tri_Mask 
  --render_TDOM 
  --GSD_x 0.00
  --GSD_y 0.00
```

Due to the absence of GCPs, **On-the-Fly SfM** performs camera pose estimation
and sparse point cloud reconstruction in a relative coordinate system.
As a result, the scale of the coordinate system may vary across different runs of **3DGS training** and **TDOM generation**.

Therefore, we temporarily set `--GSD_x` and `--GSD_y` to `0`,
allowing the system to automatically determine the appropriate GSD
for each rendering based on the current scene scale.

# Linux Env Setting

If you are configuring the Python environment for **A-TDOM** on **Linux**,
please use the following command directly:

```shell
# Env
cd .../A-TDOM
conda env create --file environment.yml
conda activate ATDOM

pip install pytorch3d
pip install opencv-python
pip install lpips
pip install scikit-image
```

# Linux Run

Since **On-the-Fly SfM** is not currently available on **Linux**, 
running **A-TDOM** on Linux requires first executing **On-the-Fly SfM** on **Windows** and saving the intermediate results.
These results should then be transferred to the Linux environment to proceed with subsequent **3DGS training** and **TDOM generation**.

In this project, we provide executable versions of **On-the-Fly SfM**,
which are stored in the corresponding folder with the same name.
If you would like to learn how to export the intermediate results, please refer to [Data Preparation](#data-preparation).

## Before Run

If the intermediate results generated by **On-the-Fly SfM** are stored in `Source_Path_Dir`,
and the image data are stored in `Image_Folder_Path`,
your directory structure should be organized as follows:

*****************************************

.../Image_Folder_Path\
=> 0001.jpg, 0002.jpg, 0003.jpg, ...

.../Source_Path_Dir\
=> GaussianSplatting\
==> 3\
===> bin, ...\
==> 4\
===> bin, ...\
...

*****************************************

## 3DGS Training and TDOM Generation

If you would like to output the results of **3DGS training** to `Model_Path_Dir`, 
please run the following command to perform 3DGS training:

```shell
python ContinuosProgressiveTrain4.py 
  --Source_Path_Dir .../your_path 
  --Model_Path_Dir .../your_path 
  --Image_Folder_Path .../your_path 
  --OriginImageHeight [int] 
  --OriginImageWidth [int] 
  --points_per_triangle [int] 
  --LogMaskThreshold [float] 
  --Use_Tri_Mask
```

If you would like to generate **TDOM** simultaneously during training,
please run the following command:

```shell
python ContinuosProgressiveTrain4.py 
  --Source_Path_Dir .../your_path 
  --Model_Path_Dir .../your_path 
  --Image_Folder_Path .../your_path 
  --OriginImageHeight [int] 
  --OriginImageWidth [int] 
  --points_per_triangle [int] 
  --LogMaskThreshold [float] 
  --Use_Tri_Mask
  --render_TDOM 
  --GSD_x [float] 
  --GSD_y [float]
```

<details>
<summary><span style="font-weight: bold;">Necessary command Line Arguments for ContinuosProgressiveTrain4.py</span></summary>

  #### --Source_Path_Dir {str}
  Path to the source directory containing all camera pose information and sparse point cloud.
  #### --Model_Path_Dir {str}
  Path where the trained model should be stored.
  #### --Image_Folder_Path {str}
  Path to directory containing all image data.
  #### --IterationFirstScene {int}
  Training iterations for initial training phase.
  #### --FinalOptimizationIterations {int}
  Training iterations for final refinement phase.
  #### --StartFromImageNo {int}
  It indicates from which image the progressive training begins. This image and all the images before it are used for scene initialization.
  #### --OriginImageHeight {int}
  The original image height input into On-Fly SfM.
  #### --OriginImageWidth {int}
  The original image width input into On-Fly SfM.
  #### --points_per_triangle {int}
  The number of points collected in each triangle when conducting point sampling based on the Delunay triangulation.
  #### --LogMaskThreshHold {float}
  Gradient difference threshold used to determine whether new Gaussians should be added. A larger value results in fewer Gaussians being added, while a smaller value leads to more.
  #### --NoDebug
  When enabled, rendering quality evaluation is disabled during progressive 3DGS training.
  #### --Use_Tri_Mask
  When enabled, use the mask generated from Delaunay Triangulation for 3DGS training.
  #### --render_RGB
  When enabled, the newly added image is rendered after completing the training stage for each new image.
  #### --render_TDOM
  When enabled, orthogonal splatting is performed on the current 3DGS field after each training stage, and a TDOM is generated.
  #### --GetDemo
  When enabled, a demo is generated based on the rendered results during training. This option must be used together with `--render_RGB` or `--render_TDOM`.
  #### --GSD_x {float}
  GSD of the generated TDOM along the Y-axis. If set to `0`, the GSD will be automatically determined.
  #### --GSD_y {float}
  GSD of the generated TDOM along the Y-axis. If set to `0`, the GSD will be automatically determined.

</details>

## Example

We use the **phantom3-ieu** dataset
(you can download it [here](https://www.adv-ci.com/blog/source/npu-drone-map-dataset/))
as an example. The following command demonstrates how to perform 3DGS training with simultaneous TDOM generation:

```shell
python ContinuosProgressiveTrain4.py 
  --Source_Path_Dir .../phantom3-ieu 
  --Model_Path_Dir .../phantom3-ieu 
  --Image_Folder_Path .../images 
  --OriginImageHeight 1049 
  --OriginImageWidth 1870 
  --points_per_triangle 30 
  --LogMaskThreshold 0.15 
  --Use_Tri_Mask 
  --render_TDOM 
  --GSD_x 0.00
  --GSD_y 0.00
```

Due to the absence of GCPs, **On-the-Fly SfM** performs camera pose estimation
and sparse point cloud reconstruction in a relative coordinate system.
As a result, the scale of the coordinate system may vary across different runs of **3DGS training** and **TDOM generation**.

Therefore, we temporarily set `--GSD_x` and `--GSD_y` to `0`,
allowing the system to automatically determine the appropriate GSD
for each rendering based on the current scene scale.

# Data Preparation



# BibTex

```shell
@article{ATDOM,
  title={A-TDOM: Active TDOM via On-the-Fly 3DGS},
  author={Xu, Yiwei and Wang, Xiang and Yu, Yifei and Gan, Wentian and Morelli, Luca and Perda, Giulio and Xiao, Xiongwu and Zhan, Zongqian and Wang, Xin and Remondino, Fabio},
  journal={arXiv preprint arXiv:2509.12759},
  year={2025}
}
```